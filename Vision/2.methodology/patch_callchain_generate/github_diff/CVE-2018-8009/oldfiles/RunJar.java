package org.apache.hadoop.util;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.net.MalformedURLException;
import java.net.URL;
import java.net.URLClassLoader;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Enumeration;
import java.util.List;
import java.util.jar.JarEntry;
import java.util.jar.JarFile;
import java.util.jar.Manifest;
import java.util.regex.Pattern;
import org.apache.hadoop.classification.InterfaceAudience;
import org.apache.hadoop.classification.InterfaceStability;
import org.apache.hadoop.fs.FileUtil;
import org.apache.hadoop.io.IOUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
@InterfaceAudience.Private
@InterfaceStability.Unstable
public class RunJar {
  private static final Logger LOG = LoggerFactory.getLogger(RunJar.class);
  public static final Pattern MATCH_ANY = Pattern.compile(".*");
  public static final int SHUTDOWN_HOOK_PRIORITY = 10;
  public static final String HADOOP_USE_CLIENT_CLASSLOADER = "HADOOP_USE_CLIENT_CLASSLOADER";
  public static final String HADOOP_CLASSPATH = "HADOOP_CLASSPATH";
  public static final String HADOOP_CLIENT_CLASSLOADER_SYSTEM_CLASSES = "HADOOP_CLIENT_CLASSLOADER_SYSTEM_CLASSES";
  private static final int BUFFER_SIZE = 8_192;
  public static void unJar(File jarFile, File toDir) throws IOException {
    unJar(jarFile, toDir, MATCH_ANY);
  }
  
  public static void unJar(File jarFile, File toDir, Pattern unpackRegex) throws IOException {
    try (JarFile jar = new JarFile(jarFile)) {
      int numOfFailedLastModifiedSet = 0;
      Enumeration<JarEntry> entries = jar.entries();
      while (entries.hasMoreElements()) {
        final JarEntry entry = entries.nextElement();
        if (!entry.isDirectory() && unpackRegex.matcher(entry.getName()).matches()) {
          try (InputStream in = jar.getInputStream(entry)) {
            File file = new File(toDir, entry.getName());
            ensureDirectory(file.getParentFile());
            try (OutputStream out = new FileOutputStream(file)) {
              IOUtils.copyBytes(in, out, BUFFER_SIZE);
            }
            
            if (!file.setLastModified(entry.getTime())) {
              numOfFailedLastModifiedSet++;
            }
            
          }
          
        }
        
      }
      
      if (numOfFailedLastModifiedSet > 0) {
        LOG.warn("Could not set last modfied time for {} file(s)", numOfFailedLastModifiedSet);
      }
      
    }
    
  }
  
  private static void ensureDirectory(File dir) throws IOException {
    if (!dir.mkdirs() && !dir.isDirectory()) {
      throw new IOException("Mkdirs failed to create " + dir.toString());
    }
    
  }
  
  public static void main(String[] args) throws Throwable {
    new RunJar().run(args);
  }
  
  public void run(String[] args) throws Throwable {
    String usage = "RunJar jarFile [mainClass] args...";
    if (args.length < 1) {
      System.err.println(usage);
      System.exit(-1);
    }
    
    int firstArg = 0;
    String fileName = args[firstArg++];
    File file = new File(fileName);
    if (!file.exists() || !file.isFile()) {
      System.err.println("JAR does not exist or is not a normal file: " + file.getCanonicalPath());
      System.exit(-1);
    }
    
    String mainClassName = null;
    JarFile jarFile;
    try {
      jarFile = new JarFile(fileName);
    }
     catch (IOException io) {
      throw new IOException("Error opening job jar: " + fileName) .initCause(io);
    }
    
    Manifest manifest = jarFile.getManifest();
    if (manifest != null) {
      mainClassName = manifest.getMainAttributes().getValue("Main-Class");
    }
    
    jarFile.close();
    if (mainClassName == null) {
      if (args.length < 2) {
        System.err.println(usage);
        System.exit(-1);
      }
      
      mainClassName = args[firstArg++];
    }
    
    mainClassName = mainClassName.replaceAll("/", ".");
    File tmpDir = new File(System.getProperty("java.io.tmpdir"));
    ensureDirectory(tmpDir);
    final File workDir;
    try {
      workDir = File.createTempFile("hadoop-unjar", "", tmpDir);
    }
     catch (IOException ioe) {
      System.err.println("Error creating temp dir in java.io.tmpdir " + tmpDir + " due to " + ioe.getMessage());
      System.exit(-1);
      return;
    }
    
    if (!workDir.delete()) {
      System.err.println("Delete failed for " + workDir);
      System.exit(-1);
    }
    
    ensureDirectory(workDir);
    ShutdownHookManager.get().addShutdownHook( new Runnable() {
          @Override
          public void run() {
            FileUtil.fullyDelete(workDir);
          }
          
        }, SHUTDOWN_HOOK_PRIORITY);
    unJar(file, workDir);
    ClassLoader loader = createClassLoader(file, workDir);
    Thread.currentThread().setContextClassLoader(loader);
    Class<?> mainClass = Class.forName(mainClassName, true, loader);
    Method main = mainClass.getMethod("main", String[].class);
    List<String> newArgsSubList = Arrays.asList(args) .subList(firstArg, args.length);
    String[] newArgs = newArgsSubList .toArray(new String[newArgsSubList.size()]);
    try {
      main.invoke(null, new Object[] {newArgs});
    }
     catch (InvocationTargetException e) {
      throw e.getTargetException();
    }
    
  }
  
  private ClassLoader createClassLoader(File file, final File workDir) throws MalformedURLException {
    ClassLoader loader;
    if (useClientClassLoader()) {
      StringBuilder sb = new StringBuilder();
      sb.append(workDir).append("/"). append(File.pathSeparator).append(file). append(File.pathSeparator).append(workDir).append("/classes/"). append(File.pathSeparator).append(workDir).append("/lib/*");
      String hadoopClasspath = getHadoopClasspath();
      if (hadoopClasspath != null && !hadoopClasspath.isEmpty()) {
        sb.append(File.pathSeparator).append(hadoopClasspath);
      }
      
      String clientClasspath = sb.toString();
      String systemClasses = getSystemClasses();
      List<String> systemClassesList = systemClasses == null ? null : Arrays.asList(StringUtils.getTrimmedStrings(systemClasses));
      loader = new ApplicationClassLoader(clientClasspath, getClass().getClassLoader(), systemClassesList);
    }
     else {
      List<URL> classPath = new ArrayList<>();
      classPath.add(new File(workDir + "/").toURI().toURL());
      classPath.add(file.toURI().toURL());
      classPath.add(new File(workDir, "classes/").toURI().toURL());
      File[] libs = new File(workDir, "lib").listFiles();
      if (libs != null) {
        for (File lib : libs) {
          classPath.add(lib.toURI().toURL());
        }
        
      }
      
      loader = new URLClassLoader(classPath.toArray(new URL[classPath.size()]));
    }
    
    return loader;
  }
  
  boolean useClientClassLoader() {
    return Boolean.parseBoolean(System.getenv(HADOOP_USE_CLIENT_CLASSLOADER));
  }
  
  String getHadoopClasspath() {
    return System.getenv(HADOOP_CLASSPATH);
  }
  
  String getSystemClasses() {
    return System.getenv(HADOOP_CLIENT_CLASSLOADER_SYSTEM_CLASSES);
  }
  
}

